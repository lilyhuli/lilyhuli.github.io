<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>TangDon的博客</title>
  
  <subtitle>单口喜剧是一种人格紊乱，而我们以此为生。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="lilyhuli.github.io/"/>
  <updated>2019-03-11T16:40:19.116Z</updated>
  <id>lilyhuli.github.io/</id>
  
  <author>
    <name>TangDon</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ES 搜索</title>
    <link href="lilyhuli.github.io/2019/03/12/ES-%E6%90%9C%E7%B4%A2/"/>
    <id>lilyhuli.github.io/2019/03/12/ES-搜索/</id>
    <published>2019-03-11T16:18:32.000Z</published>
    <updated>2019-03-11T16:40:19.116Z</updated>
    
    <content type="html"><![CDATA[<p>es与kibana结合 在kibana中编写restful命令</p><p>索引（indices）——————————–Databases 数据库</p><p>​    类型（type）—————————–Table 数据表</p><p>​         文档（Document）—————-Row 行</p><p>​           字段（Field）——————-Columns 列 </p><p>映射是定义文档的过程，文档包含哪些字段，这些字段是否保存，是否索引，是否分词等</p><p>只有配置清楚，Elasticsearch才会帮我们进行索引库的创建（不一定）</p><ul><li><p>String类型，又分两种：</p><ul><li>text：可分词，不可参与聚合</li><li>keyword：不可分词，数据会作为完整字段进行匹配，可以参与聚合</li></ul></li><li><p>Numerical：数值类型，分两类</p><ul><li>基本数据类型：long、interger、short、byte、double、float、half_float</li><li>浮点数的高精度类型：scaled_float<ul><li>需要指定一个精度因子，比如10或100。elasticsearch会把真实值乘以这个因子后存储，取出时再还原。</li></ul></li></ul></li><li><p>Date：日期类型</p><p>elasticsearch可以对日期格式化为字符串存储，但是建议我们存储为毫秒值，存储为long，节省空间。</p><p>@Document(indexName = “item”,type = “docs”, shards = 1, replicas = 0)<br>public class Item {<br>  @Id<br>  private Long id;</p><p>  @Field(type = FieldType.Text, analyzer = “ik_max_word”)<br>  private String title; //标题</p><p>  @Field(type = FieldType.Keyword)<br>  private String category;// 分类</p><p>  @Field(type = FieldType.Keyword)<br>  private String brand; // 品牌</p><p>  @Field(type = FieldType.Double)<br>  private Double price; // 价格</p><p>  @Field(index = false, type = FieldType.Keyword)<br>  private String images; // 图片地址<br>}</p></li></ul><p>  Spring Data通过注解来声明字段的映射属性，有下面的三个注解：</p><ul><li><code>@Document</code> 作用在类，标记实体类为文档对象，一般有两个属性<ul><li>indexName：对应索引库名称</li><li>type：对应在索引库中的类型</li><li>shards：分片数量，默认5</li><li>replicas：副本数量，默认1</li></ul></li><li><code>@Id</code> 作用在成员变量，标记一个字段作为id主键</li><li><code>@Field</code> 作用在成员变量，标记为文档的字段，并指定字段映射属性：<ul><li>type：字段类型，取值是枚举：FieldType</li><li>index：是否索引，布尔类型，默认是true</li><li>store：是否存储，布尔类型，默认是false</li><li>analyzer：分词器名称</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;es与kibana结合 在kibana中编写restful命令&lt;/p&gt;
&lt;p&gt;索引（indices）——————————–Databases 数据库&lt;/p&gt;
&lt;p&gt;​    类型（type）—————————–Table 数据表&lt;/p&gt;
&lt;p&gt;​         文档（Do
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>随记</title>
    <link href="lilyhuli.github.io/2019/02/26/%E9%9A%8F%E8%AE%B0/"/>
    <id>lilyhuli.github.io/2019/02/26/随记/</id>
    <published>2019-02-25T16:53:57.000Z</published>
    <updated>2019-03-11T16:40:43.581Z</updated>
    
    <content type="html"><![CDATA[<p>Rabbitmq：假设P1和C1注册了相同的Broker，Exchange和Queue。P1发送的消息最终会被C1消费。基本的通信流程大概如下所示：</p><p>P1生产消息，发送给服务器端的Exchange<br>Exchange收到消息，根据ROUTINKEY，将消息转发给匹配的Queue1<br>Queue1收到消息，将消息发送给订阅者C1<br>C1收到消息，发送ACK给队列确认收到消息<br>Queue1收到ACK，删除队列中缓存的此条消息</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Rabbitmq：假设P1和C1注册了相同的Broker，Exchange和Queue。P1发送的消息最终会被C1消费。基本的通信流程大概如下所示：&lt;/p&gt;
&lt;p&gt;P1生产消息，发送给服务器端的Exchange&lt;br&gt;Exchange收到消息，根据ROUTINKEY，将消息
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>MQ面试连环炮</title>
    <link href="lilyhuli.github.io/2019/02/24/MQ%E9%9D%A2%E8%AF%95%E8%BF%9E%E7%8E%AF%E7%82%AE/"/>
    <id>lilyhuli.github.io/2019/02/24/MQ面试连环炮/</id>
    <published>2019-02-24T10:27:56.000Z</published>
    <updated>2019-02-25T17:51:37.525Z</updated>
    
    <content type="html"><![CDATA[<p><font size="4" face="黑体">1、消息队列的作用？</font><br><br></p><p><font size="2">核心3点：解耦、异步、削峰<br>1.abcd系统问题 2.大量用户通过浏览器（举办了一场活动）在中午高峰期进行了大量操作，大量系统涌入系统，比如说5000/秒,系统基于mysql，大量请求涌入mysql，每秒对mysql5000次冲击基本上挂掉，因为一般的mysql2000请求就会挂了，但是高峰期过了之后到下午就是低峰期，为了保证mysql不被打死，我们采用的方案就是加入一个mq，在请求端加入mq，系统a从mq中慢慢拉取请求，过了高峰期挤压的消息，就算不加机器一个小时也能消耗完。</font><br><br></p><p><font size="4" face="黑体">2、保证消息队列的高可用？</font><br><br></p><p><font size="2">MQ的缺点很明确，加入mq会让系统变得复杂，rabbitmq的高可用方式：rabbitmq有三种模式：单机模式，普通集群模式，镜像集群模式   1.单机模式没人用，2普通集群模式，就是在多台机器上启动多台实例，每个机器启动一个。但是你创建的queue只会在一个rabbitmq上，每个实例都会同步queue的元数据。Channel 声明队列 3.集群镜像模式 把需要的队列做成镜像队列，存在于多个节点，属于rabbitmq的ha方案。其实质和普通模式不同之处在于，消息实体会主动在镜像节点间同步，而不是在consumer取数据时临时拉取。kafka的高可用性：多个broker组成，每个broker是一个节点；你创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据。kafka 0.8以后，提供了HA机制，就是replica副本机制。每个partition的数据都会同步到吉他机器上，形成自己的多个replica副本。然后所有replica会选举一个leader出来，那么生产和消费都跟这个leader打交道，然后其他replica就是follower。</font><br><br></p><p><font size="4" face="黑体">2、保证消息队列的幂等性？</font><br><br></p><p><font size="2">业界主流的幂等性有两种操作：</font></p><p>1.唯一 ID + 指纹码 机制，利用数据库主键去重</p><p>2.利用redis的原子性去实现</p><p>kafka实际上有个offset的概念，就是每个消息写进去，都有一个offset，代表他的序号，然后consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交一下，代表我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的offset来继续消费吧。</p><p>但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接kill进程了，再重启。这会导致consumer有些消息处理了，但是没来得及提交offset，尴尬了。重启之后，少数消息会再次消费一次。<br>给你举个例子吧。假设你有个系统，消费一条往数据库里插入一条，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下已经消费过了，直接扔了，不就保留了一条数据？</p><p>一条数据重复出现两次，数据库里就只有一条数据，这就保证了系统的幂等性</p><p>幂等性，我通俗点说，就一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错。<br>其实还是得结合业务来思考，我这里给几个思路：<br>（1）比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update一下好吧</p><p>（2）比如你是写redis，那没问题了，反正每次都是set，天然幂等性</p><p>（3）比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。<br><br></p><p><font size="4" face="黑体">3、保证消息的可靠性传输（如何处理消息丢失的问题）？</font><br></p><p><font size="2">rabbitmq 1生产者弄丢了数据<br>confirm机制 2 rabbitmq弄丢了数据,设置持久化有两个步骤，第一个是创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里的数据；第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，rabbitmq哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。而且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，rabbitmq挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。3 消费端弄丢了数据 这个时候得用rabbitmq提供的ack机制，简单来说，就是你关闭rabbitmq自动ack，可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，再程序里ack一把。这样的话，如果你还没处理完，不就没有ack？那rabbitmq就认为你还没处理完，这个时候rabbitmq会把这个消费分配给别的consumer去处理，消息是不会丢的。kafka  kafka会自动提交offset，那么只要关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。但是此时确实还是会重复消费，比如你刚处理完，还没提交offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。 kafka弄丢了数据<br>给这个topic设置replication.factor参数：这个值必须大于1，要求每个partition必须有至少2个副本</font></p><p>在kafka服务端设置min.insync.replicas参数：这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower吧</p><p>在producer端设置acks=all：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了</p><p>在producer端设置retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了</p><p>我们生产环境就是按照上述要求配置的，这样配置之后，至少在kafka broker端就可以保证在leader所在broker发生故障，进行leader切换时，数据不会丢失<br><br><br></p><p><font size="4" face="黑体">4、保证消息的顺序性？</font><br><br></p><p><font size="2">那如何保证消息的顺序性呢？简单简单</font></p><p>（1）rabbitmq：拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理</p><p>（2）kafka：一个topic，一个partition，一个consumer，内部单线程消费，写N个内存queue，然后N个线程分别消费一个内存queue即可<br><br><br></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;font size=&quot;4&quot; face=&quot;黑体&quot;&gt;1、消息队列的作用？&lt;/font&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;font size=&quot;2&quot;&gt;核心3点：解耦、异步、削峰&lt;br&gt;1.abcd系统问题 2.大量用户通过浏览器（举办了一场活动）在中午高峰期进行了大量操作，大量
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Spring 面试题总结</title>
    <link href="lilyhuli.github.io/2019/02/16/myNewTestBlog/"/>
    <id>lilyhuli.github.io/2019/02/16/myNewTestBlog/</id>
    <published>2019-02-15T18:56:43.000Z</published>
    <updated>2019-02-22T13:34:03.825Z</updated>
    
    <content type="html"><![CDATA[<font size="4" face="黑体">1、什么是 Spring 框架？Spring 框架有哪些主要模块？</font><br><br><br><font size="2">Spring 框架是一个为 Java 应用程序的开发提供了综合、广泛的基础性支持的 Java 平台。Spring帮助开发者解决了开发中基础性的问题，使得开发人员可以专注于应用程序的开发。Spring 框架本身亦是按照设计模式精心打造，这使得我们可以在开发环境中安心的集成 Spring 框架，不必担心 Spring 是如何在后台进行工作的。Spring 框架至今已集成了 20 多个模块。这些模块主要被分如下图所示的核心容器、数据访问/集成,、Web、AOP（面向切面编程）、工具、消息和测试模块。</font><br><br><br><font size="4" face="黑体">2、Spring 框架中都用到了哪些设计模式？</font><br><br><br><font size="2">Spring 框架中使用到了大量的设计模式，下面列举了比较有代表性的：1、代理模式—在 AOP 和 remoting 中被用的比较多。2、单例模式：在 spring 配置文件中定义的 bean 默认为单例模式。3、模板模式：用来解决代码重复的问题。比如. RestTemplate, JmsTemplate, JpaTemplate。4、委派模式：Spring 提供了 DispatcherServlet 来对请求进行分发。5、工厂模式：BeanFactory 用来创建对象的实例，贯穿于 BeanFactory / ApplicationContext接口的核心理念。6、代理模式：AOP 思想的底层实现技术，Spring 中采用 JDK Proxy 和 CgLib 类库。</font>]]></content>
    
    <summary type="html">
    
      
      
        &lt;font size=&quot;4&quot; face=&quot;黑体&quot;&gt;1、什么是 Spring 框架？Spring 框架有哪些主要模块？&lt;/font&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;font size=&quot;2&quot;&gt;Spring 框架是一个为 Java 应用程序的开发提供了综合、广泛的基础性支持的 Java 平
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>秒杀，了解一下</title>
    <link href="lilyhuli.github.io/2019/01/18/%E7%A7%92%E6%9D%80%EF%BC%8C%E4%BA%86%E8%A7%A3%E4%B8%80%E4%B8%8B/"/>
    <id>lilyhuli.github.io/2019/01/18/秒杀，了解一下/</id>
    <published>2019-01-18T14:33:45.000Z</published>
    <updated>2019-01-18T14:35:57.058Z</updated>
    
    <content type="html"><![CDATA[<h1 id="秒杀"><a href="#秒杀" class="headerlink" title="秒杀"></a>秒杀</h1><p>一个关于秒杀的故事 记录学习和工作点滴</p><p>学习了redis和rabbitmq一直没有很好地应用，秒杀业务可以使用redis预减库存、消息队列异步下单逐级消减对数据库的访问；mysql最大的并发量才1000，</p><p>所以瓶颈基本都是在数据库</p><p>因为是前端菜鸟所以使用bootstrap jq 和后端的thymeleaf 中间件用rabbitmq/redis/druid；</p><p>系统支持横向拓展，集群，优化缓存 异步下单 消峰 验证码框架也是用的数学验证最大强度的防止机器人；</p><p>自己封装的jedis更易使用 使用jedisTemplate主要是spring给了cache功能，这里直接自己封装的。</p><p>未完待续。</p><p>项目地址：<a href="https://github.com/lilyhuli/miaosha" target="_blank" rel="noopener">https://github.com/lilyhuli/miaosha</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;秒杀&quot;&gt;&lt;a href=&quot;#秒杀&quot; class=&quot;headerlink&quot; title=&quot;秒杀&quot;&gt;&lt;/a&gt;秒杀&lt;/h1&gt;&lt;p&gt;一个关于秒杀的故事 记录学习和工作点滴&lt;/p&gt;
&lt;p&gt;学习了redis和rabbitmq一直没有很好地应用，秒杀业务可以使用redis预减库
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>springsecurity整合jwt</title>
    <link href="lilyhuli.github.io/2019/01/14/springsecurity%E6%95%B4%E5%90%88jwt/"/>
    <id>lilyhuli.github.io/2019/01/14/springsecurity整合jwt/</id>
    <published>2019-01-14T14:17:54.000Z</published>
    <updated>2019-01-14T14:18:57.976Z</updated>
    
    <content type="html"><![CDATA[<h1 id="springsecurity-jwt"><a href="#springsecurity-jwt" class="headerlink" title="springsecurity_jwt"></a>springsecurity_jwt</h1><p>springsecurity结合jwt<br>今天写下Spring Security整合jwt的一个简单小Demo，目的是登录后实现返回token</p><p>明天整合通用树形显示和vue前端显示 现在只能通过postman简单测试</p><p>jwt存在争议，但是很容易上手，分布式场景下不能再用ck-session的组合了</p><p>经典的三表结构比昨天的demo更有工业价值，代码放在Github上了 <a href="https://github.com/lilyhuli/springsecurity_jwt/" target="_blank" rel="noopener">https://github.com/lilyhuli/springsecurity_jwt/</a> 欢迎大家star、issues</p><p>ps：郁闷的七牛云图床必须要绑定备案域名了，后来发现issues直接拖拽就能当做图床，还是不要滥用呀。</p><p><img src="https://user-images.githubusercontent.com/32732399/51117727-956ae280-1849-11e9-8693-eb8787d27935.jpg" alt="Image text"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;springsecurity-jwt&quot;&gt;&lt;a href=&quot;#springsecurity-jwt&quot; class=&quot;headerlink&quot; title=&quot;springsecurity_jwt&quot;&gt;&lt;/a&gt;springsecurity_jwt&lt;/h1&gt;&lt;p&gt;spring
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Spring Security </title>
    <link href="lilyhuli.github.io/2019/01/14/Spring-Security/"/>
    <id>lilyhuli.github.io/2019/01/14/Spring-Security/</id>
    <published>2019-01-13T16:34:56.000Z</published>
    <updated>2019-01-13T16:44:31.591Z</updated>
    
    <content type="html"><![CDATA[<p>   趁着周末闲来无事学习了一下Spring Security，源码在 <a href=""></a>lilyhuli/spring_security_exam</p><p>   用到的技术：<br>   java<br>   springboot<br>   mybatis<br>   mysql<br>   后端框架thymeleaf</p><p>需求如下：<br>Security中可以在内存中建立用户，留后门设置后门账号，以及数据库的结合访问。<br>和shiro一样 不同用户拥有不同权限，访问不同网页。<br>如果用户未登录，则返回首页，如果用户已登录，但是没有权限则返回json，告知。</p><pre><code>网上的看了很多文章，Spring Security内置了三个基于投票，AccessDecisionManager实现类，它们分别是AffirmativeBased、ConsensusBased 和UnanimousBased。我觉得继承AccessDecisionManager，然后重写decide方法就可以。当然Spring Security的代码需要一点点debug才能了解其原理。搞完又过0点了，洗洗睡了，梦里啥都有。</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;   趁着周末闲来无事学习了一下Spring Security，源码在 &lt;a href=&quot;&quot;&gt;&lt;/a&gt;lilyhuli/spring_security_exam&lt;/p&gt;
&lt;p&gt;   用到的技术：&lt;br&gt;   java&lt;br&gt;   springboot&lt;br&gt;   mybat
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>又是一年末尾</title>
    <link href="lilyhuli.github.io/2018/12/25/%E5%8F%88%E6%98%AF%E4%B8%80%E5%B9%B4%E6%9C%AB%E5%B0%BE/"/>
    <id>lilyhuli.github.io/2018/12/25/又是一年末尾/</id>
    <published>2018-12-24T16:31:00.000Z</published>
    <updated>2019-01-13T16:33:42.291Z</updated>
    
    <content type="html"><![CDATA[<p>这一年不仅没有完成爸妈所说的人生大事，还把工作搞得一团糟。读了几本书，看了几部剧，就想把感想和经历写下来，毕竟好多年都没写总结了。</p><p>  1，《简爱》 </p><pre><code>长大了再读《简爱》真觉得简爱是一个自怨自艾的玛丽苏，根本没有灰姑娘的容颜，也没有纯洁谦卑，外柔内刚的品质，有的只是孤傲清高，目中无人，乖戾而非可爱，敏感且自卑，自我为中心，童年的经历给了她太多不幸，当然也影响了她的决定，她本不该，出身无法决定，但能决定的一定要好好把握；而《呼啸山庄》那种坏就是要坏的彻底，悲剧就是要绑架你；</code></pre><p>  2，《东京女子图鉴》</p><pre><code>绫在干什么？同作为一个京漂，绫这么富有野心，怎么可能找到和她一样的人呢，她看不起自己的阶层，厌恶自己的出身，她并不喜欢自己，努力去除自己身上的土气，那个面对阶级凝固努力想要嫁入上层阶级的绫，真当有平配自己的伴侣在一起时，要么嫌过于平凡，要么觉得对方野心太重，要么觉得对方无聊，最后都不欢而散，她只喜欢自己高攀不起的港区男，同样港区男是不会选择她的。成熟后的人多可怕，没有感情波动，和《黑镜》里玩大数据匹配伴侣的那集很像，不过黑镜的结局都要好过图鉴了，大多数东京人在工作中挣扎着对感情的投入太有限了。不过这样才显得更真实，毕竟电视剧和小说放大了感情，让你觉得它很重要；作为职业白领，绫的结婚只是她的一个目标，日本压抑的社会关系真让人喘不过气，偶像剧是泛娱乐时代的毒品，从早到晚谈恋爱，贫女出门遇见高富帅。</code></pre><p>3， 极简生活</p><pre><code>加入极简生活小组之后，发现大多数人的极简主义就是扔扔扔，这是一种的变相的消费升级，不是极简主义。对于像我这么穷的人来说，极简主义是断舍离，减物欲。购买物品所带来的快感实在太短了，在精美的包装下它让人非常期待，一旦拆开，我就要担心它会不会又磕伤划痕，变旧过时，这样所带来的只能是重蹈覆辙，不断陷入消费主义的陷阱里，不能自拔，这就非常恐怖了；我不是一个批判家，也没有资格判断，社会的标尺太沉重，对错正邪都只是前人框定好的，没有机会去定义，没有勇气去改变，更不是为了安利极简主义的生活方式，生活方式是自己决定的，根本没有对错，只要能让自己内心充盈，关注更重要的事，不必为了琐碎浪费时间。</code></pre><p>4， 情感</p><pre><code>在我看来，爱情在只不过是一小段插曲，是日常生活中诸多事务中的一件小事，这些都是从我的斗争经历里得出的。喜欢你的人会把你的沉默寡言看成斯文乖巧，莽撞冒失也可以是可爱娇痴，甚至脾气暴躁都可以是豁达爽朗；不喜欢你的人则把关心当做打扰，沉默当成冷落，你精心准备的心思会被当做神经质。所以形容词最不靠谱，舔狗也不得house。就没有那种成熟平等的恋爱么，再炙热也不过火，再沉默也不觉得是冷漠。恐惧不期而遇的爱蔓延，那种没有回应的尴尬和苦涩。毛姆不就说： “女人可以原谅男人伤害他，但绝不能原谅男人为她做出牺牲” ，毛姆是一个仇女的人，但他这句话说的很对。《一千零一夜》里的王后会沉迷每天对她暴虐的人，但是却对爱她的国王熟视无睹；所以不要对一个不爱你的人好，只会让自己显得更廉价。</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这一年不仅没有完成爸妈所说的人生大事，还把工作搞得一团糟。读了几本书，看了几部剧，就想把感想和经历写下来，毕竟好多年都没写总结了。&lt;/p&gt;
&lt;p&gt;  1，《简爱》 &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;长大了再读《简爱》真觉得简爱是一个自怨自艾的玛丽苏，根本没有灰姑娘的容颜，也没
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>RabbitMQ 相关</title>
    <link href="lilyhuli.github.io/2018/05/14/RabbitMQ-%E7%9B%B8%E5%85%B3-2/"/>
    <id>lilyhuli.github.io/2018/05/14/RabbitMQ-相关-2/</id>
    <published>2018-05-13T16:28:00.000Z</published>
    <updated>2019-01-13T16:29:50.559Z</updated>
    
    <content type="html"><![CDATA[<p>摘要： 使用RabbitMQ的消息队列，可以有效提高系统的峰值处理能力。</p><p>RabbitMQ是消息代理(Message Broker)，它支持多种异步消息处理方式，最常见的有：</p><p>Work Queue：将消息缓存到一个队列，默认情况下，多个worker按照Round Robin的方式处理队列中的消息。每个消息只会分配给单个worker。</p><p>Publish/Subscribe：每个订阅消息的消费者都会收到消息，因此每个消息通常会分配给多个worker，每个worker对消息进行不同的处理。</p><p>RabbitMQ还支持Routing、Topics、以及Remote procedure calls (RPC)等方式。</p><p>对于不同的消息处理方式，有一点是相同的，RabbitMQ是介于消息的生产者和消费者的中间节点，负责缓存和分发消息。RabbitMQ接收来自生产者的消息，缓存到内存中，按照不同的方式分发给消费者。RabbitMQ还可以将消息写入磁盘，保证持久化，这样即使RabbitMQ意外崩溃了，消息数据不至于完全丢失。</p><p>为什么使用RabbitMQ？</p><p>最简单的一点在于，它支持Work Queue等不同的消息处理方式，可以用于不同的业务场景。RabbitMQ的Work Queue，即消息队列。</p><p>使用消息队列，可以将不算紧急、但是非常消耗资源的计算任务，以消息的方式插入到RabbitMQ的队列中，然后使用多个处理模块处理这些消息。</p><p>这样做最大的好处在于：提高了系统峰值处理能力。因为，来不及处理的消息缓存在RabbitMQ中，避免了同时进行大量计算导致系统因超负荷运行而崩溃。而那些来不及处理的消息，会在峰值过去之后慢慢处理掉。</p><p>另一个好处在于解耦。消息的生产者只需要将消息发送给RabbitMQ，这些消息什么时候处理完，不会影响生产者的响应性能。</p><p>安装并运行RabbitMQ</p><p>使用Docker运行RabbitMQ非常简单，只需要执行一条简单的命令：</p><p>sudo docker run -d –name rabbitmq -h rabbitmq -p 5672:5672 -v /var/lib/rabbitmq:/var/lib/rabbitmq registry.docker-cn.com/library/rabbitmq:3.7</p><p>-d : 后台运行容器</p><p>–name rabbitmq : 将容器的名字设为rabbitmq</p><p>-h rabbitmq : 将容器的主机名设为rabbitmq，希望RabbitMQ消息数据持久化保存到本地磁盘是需要设置主机名，因为RabbitMQ保存数据的目录为主机名</p><p>-p 5672:5672 : 将容器的5672端口映射为本地主机的5672端口，这样可以通过本地的5672端口访问rabbitmq</p><p>-v /var/lib/rabbitmq:/var/lib/rabbitmq：将容器的/var/lib/rabbitmq目录映射为本地主机的/var/lib/rabbitmq目录，这样可以将RabbitMQ消息数据持久化保存到本地磁盘，即使RabbitMQ容器被删除，数据依然还在。</p><p>消费者的消息确认机制</p><p>rabbitmq怎么知道消息被接受了呢？</p><p>acknowledge 确认机制  用手动模式</p><p>work消息模型（任务模型）</p><p>队列里的消息越来越多，内存总有存满的一天消息会丢失，消息堆积。耗时较长的比如发短信，需要用mq。</p><p>让多个消费者绑定一个队列，共同消费队列中的消息。队列中的消息一旦消费，就会消失，因此任务是不会被重复执行的。</p><p>channel.basicQos(1); 设置每次消费一个信息，解决消息堆积问题。</p><p>2.3.订阅模型分类</p><p>1、1个生产者，多个消费者</p><p>2、每一个消费者都有自己的一个队列</p><p>3、生产者没有将消息直接发送到队列，而是发送到了交换机</p><p>4、每个队列都要绑定到交换机</p><p>5、生产者发送的消息，经过交换机到达队列，实现一个消息被多个消费者获取的目的</p><p>X（Exchanges）：交换机一方面：接收生产者发送的消息。另一方面：知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange的类型。</p><p>Exchange类型有以下几种：</p><pre><code>Fanout：广播，将消息交给所有绑定到交换机的队列Direct：定向，把消息交给符合指定routing key 的队列Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列</code></pre><p>我们这里先学习</p><p>Fanout：即广播模式</p><p>Exchange（交换机）只负责转发消息，不具备存储消息的能力，因此如果没有任何队列与Exchange绑定，或者没有符合路由规则的队列，那么消息会丢失！</p><p>订阅模型-Fanout</p><p>1） 可以有多个消费者</p><p>2）  每个消费者有自己的queue（队列）</p><p>3）  每个队列都要绑定到Exchange（交换机）</p><p>4）  生产者发送的消息，只能发送到交换机，交换机来决定要发给哪个队列，生产者无法决定。</p><p>5）  交换机把消息发送给绑定过的所有队列</p><p>6）  队列的消费者都能拿到消息。实现一条消息被多个消费者消费</p><p>两个变化：</p><p>1）  声明Exchange，不再声明Queue</p><p>2）  发送消息到Exchange，不再发送到Queue</p><p>步骤：</p><p>// 获取到连接</p><p>// 获取通道</p><p>// 声明队列</p><p>// 绑定队列到交换机</p><p>// 定义队列的消费者</p><p>// 获取消息，并且处理，这个方法类似事件监听，如果有消息的时候，会被自动调用</p><p>// 监听队列，手动返回完成</p><p>订阅模型-Direct</p><p>有选择性的接收消息</p><p>在订阅模式中，生产者发布消息，所有消费者都可以获取所有消息。</p><p>在路由模式中，我们将添加一个功能 - 我们将只能订阅一部分消息。 例如，我们只能将重要的错误消息引导到日志文件（以节省磁盘空间），同时仍然能够在控制台上打印所有日志消息。</p><p>但是，在某些场景下，我们希望不同的消息被不同的队列消费。这时就要用到Direct类型的Exchange。</p><p>在Direct模型下，队列与交换机的绑定，不能是任意绑定了，而是要指定一个RoutingKey（路由key）</p><p>消息的发送方在向Exchange发送消息时，也必须指定消息的routing key</p><p>绑定队列到交换机，同时指定需要订阅的routing key。需要 update、delete</p><p>订阅模型-Topic</p><p>Topic类型的Exchange与Direct相比，都是可以根据RoutingKey把消息路由到不同的队列。只不过Topic类型Exchange可以让队列在绑定Routing key 的时候使用通配符！</p><p>Routingkey 一般都是有一个或多个单词组成，多个单词之间以”.”分割，例如： item.insert</p><p>通配符规则：</p><pre><code>#：匹配一个或多个词*：匹配不多不少恰好1个词</code></pre><p>举例：</p><pre><code>audit.#：能够匹配audit.irs.corporate 或者 audit.irsaudit.*：只能匹配audit.irs</code></pre><p>面试题：</p><p>如何避免消息丢失？</p><p>1）  消费者的ACK机制。可以防止消费者丢失消息。</p><p>2）  但是，如果在消费者消费之前，MQ就宕机了，消息就没了。</p><p>是可以将消息进行持久化呢？</p><p>要将消息持久化，前提是：队列、Exchange都持久化</p><p>durable 持久化</p><p>AmqpTemplate 统一的spring消息处理模板；</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;摘要： 使用RabbitMQ的消息队列，可以有效提高系统的峰值处理能力。&lt;/p&gt;
&lt;p&gt;RabbitMQ是消息代理(Message Broker)，它支持多种异步消息处理方式，最常见的有：&lt;/p&gt;
&lt;p&gt;Work Queue：将消息缓存到一个队列，默认情况下，多个worke
      
    
    </summary>
    
      <category term="编程人生" scheme="lilyhuli.github.io/categories/%E7%BC%96%E7%A8%8B%E4%BA%BA%E7%94%9F/"/>
    
    
      <category term="java" scheme="lilyhuli.github.io/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>丝袜哥</title>
    <link href="lilyhuli.github.io/2018/04/22/swagger/"/>
    <id>lilyhuli.github.io/2018/04/22/swagger/</id>
    <published>2018-04-22T05:40:00.000Z</published>
    <updated>2019-01-13T16:17:38.270Z</updated>
    
    <content type="html"><![CDATA[<p>1.2.Swagger-UI</p><p>丝袜哥</p><p>1.2.1.什么是OpenAPI</p><p>随着互联网技术的发展，现在的网站架构基本都由原来的后端渲染，变成了：前端渲染、前后端分离的形态，而且前端技术和后端技术在各自的道路上越走越远。  前端和后端的唯一联系，变成了API接口；API文档变成了前后端开发人员联系的纽带，变得越来越重要。</p><p>没有API文档工具之前，大家都是手写API文档的，在什么地方书写的都有，而且API文档没有统一规范和格式，每个公司都不一样。这无疑给开发带来了灾难。</p><p>OpenAPI规范（OpenAPI Specification 简称OAS）是Linux基金会的一个项目，试图通过定义一种用来描述API格式或API定义的语言，来规范RESTful服务开发过程。目前V3.0版本的OpenAPI规范已经发布并开源在github上 。</p><p>官网：<a href="https://github.com/OAI/OpenAPI-Specification" target="_blank" rel="noopener">https://github.com/OAI/OpenAPI-Specification</a></p><p>1.2.2.什么是swagger？</p><p>OpenAPI是一个编写API文档的规范，然而如果手动去编写OpenAPI规范的文档，是非常麻烦的。而Swagger就是一个实现了OpenAPI规范的工具集。</p><p>官网：<a href="https://swagger.io/" target="_blank" rel="noopener">https://swagger.io/</a></p><p>Swagger包含的工具集：</p><p>Swagger编辑器： Swagger Editor允许您在浏览器中编辑YAML中的OpenAPI规范并实时预览文档。</p><p>Swagger UI： Swagger UI是HTML，Javascript和CSS资产的集合，可以从符合OAS标准的API动态生成漂亮的文档。</p><p>Swagger Codegen：允许根据OpenAPI规范自动生成API客户端库（SDK生成），服务器存根和文档。</p><p>Swagger Parser：用于解析来自Java的OpenAPI定义的独立库</p><p>Swagger Core：与Java相关的库，用于创建，使用和使用OpenAPI定义</p><p>Swagger Inspector（免费）： API测试工具，可让您验证您的API并从现有API生成OpenAPI定义</p><p>SwaggerHub（免费和商业）： API设计和文档，为使用OpenAPI的团队构建。</p><p>常用注解说明</p><p>/**</p><p>@Api：修饰整个类，描述Controller的作用</p><p>@ApiOperation：描述一个类的一个方法，或者说一个接口</p><p>@ApiParam：单个参数描述</p><p>@ApiModel：用对象来接收参数</p><p>@ApiProperty：用对象接收参数时，描述对象的一个字段</p><p>@ApiResponse：HTTP响应其中1个描述</p><p>@ApiResponses：HTTP响应整体描述</p><p>@ApiIgnore：使用该注解忽略这个API</p><p>@ApiError ：发生错误返回的信息</p><p>@ApiImplicitParam：一个请求参数</p><p>@ApiImplicitParams：多个请求参数</p><p>*/</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.2.Swagger-UI&lt;/p&gt;
&lt;p&gt;丝袜哥&lt;/p&gt;
&lt;p&gt;1.2.1.什么是OpenAPI&lt;/p&gt;
&lt;p&gt;随着互联网技术的发展，现在的网站架构基本都由原来的后端渲染，变成了：前端渲染、前后端分离的形态，而且前端技术和后端技术在各自的道路上越走越远。  前端和后端的唯
      
    
    </summary>
    
      <category term="编程人生" scheme="lilyhuli.github.io/categories/%E7%BC%96%E7%A8%8B%E4%BA%BA%E7%94%9F/"/>
    
    
      <category term="java" scheme="lilyhuli.github.io/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>hexo博客的诞生</title>
    <link href="lilyhuli.github.io/2017/11/10/hexo/"/>
    <id>lilyhuli.github.io/2017/11/10/hexo/</id>
    <published>2017-11-10T09:52:00.000Z</published>
    <updated>2018-01-07T17:35:48.249Z</updated>
    
    <content type="html"><![CDATA[<p>该博客托管在github pages上，所以免去了备案等手续，域名还没有申请，暂时先用github的<br>。</p>   <p>友：市面上已经有很多现成的博客平台，为什么还要自己搭建一个？<br><br>   我：想到搭建的目的，一来是自己的拖延症越来越严重，一点点小借口都能摧毁曾经燃起的雄雄壮志，做一个独立博客，记录生活点滴，技术感悟，望自己能成长的快些；二来作为个人营销的门面，喜欢卖弄和自我营销的我当然还建一个独立的博客，简单的博客没什么技术含量，所以才更注重内容，符合极简主义的定位。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;该博客托管在github pages上，所以免去了备案等手续，域名还没有申请，暂时先用github的&lt;br&gt;。&lt;/p&gt;


   &lt;p&gt;友：市面上已经有很多现成的博客平台，为什么还要自己搭建一个？&lt;br&gt;&lt;br&gt;   我：想到搭建的目的，一来是自己的拖延症越来越严重，一点点
      
    
    </summary>
    
    
      <category term="hexo" scheme="lilyhuli.github.io/tags/hexo/"/>
    
  </entry>
  
</feed>
